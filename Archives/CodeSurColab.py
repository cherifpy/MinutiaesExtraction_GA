# -*- coding: utf-8 -*-
"""TestAlgoGenetique2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tPlvwNa1TB2cSPeL-OvfMVmCfXNFqmBi

Algo genetique avec:
- un crossover sur la 1 et 2 parties suelement
- Crossover uniform 
- reduire l'espace de recherche
- Encodage Statique

#1. Importer DataSet
"""

#from google.colab import drive
#drive.mount('/content/drive')

#!cp "/content/drive/MyDrive/Colab Notebooks/Projet Master/DataSets/BaseDeDonnees_2.zip" minutiae_detection.zip

from zipfile import ZipFile

print("Deecompression .....")
with ZipFile('minutiae_detection.zip') as zip:
    zip.extractall('Dataset')

"""#2. Loads libs"""

import numpy as np
import tensorflow as tf
from keras.models import Model, Sequential
from keras.layers import Conv2D, Dense, Input, MaxPool2D, Dropout, Activation, Normalization, Flatten, Reshape
from keras.activations import relu, softmax
from keras.optimizers import SGD, Adam
from sklearn.model_selection import train_test_split
from keras.preprocessing.image import ImageDataGenerator
import random 
from itertools import combinations
import pandas as pd
import datetime
import csv
import cv2 as cv
import os
import time
import json
import copy

"""#3. Model Creation"""

def CreateModel1(optimizer=None,input_shape=(),nb_classe=2, individual=[],
                    version="static",loss='categorical_crossentropy',
                    mertics="accuracy"):
    """
        Fonction de ceation du pemiere modele utilisé pour la classification des blocs
            -  Input Shape : dimension d'entré
            -  nb_classe: nombre de classe de classification dans notre cas c'est 2
            -  individual: le chromosome de l'individu
            -  version: version de l'encodage soit "dynamique" ou "statique"
            -  loss: la fonction erreur
            -  metrics: metrique d'evaluation
    """
    my_model = Sequential(name="Model")
    my_model.add(Input(shape=input_shape))
    #my_model.add(Reshape((28,28,1)))

    conv_layers = individual[0]
    dense_layers = individual[1]

    if version=="dynamic":
        for i,layer in enumerate(conv_layers):
            my_model.add(Conv2D(layer[0], layer[1], name=f'conv{i}',padding="same")) #Add conv parameters
            if layer[3] == 1: my_model.add(Activation(relu))
            if layer[2] != 0: my_model.add(MaxPool2D((layer[2],layer[2]),padding="same"))

        my_model.add(Flatten())

        for i,layer in enumerate(dense_layers):
            my_model.add(Dense(layer[0]))
            if layer[1] == 1:  my_model.add(Activation(relu))

    elif version=="static":
        for i,layer in enumerate(conv_layers):
            if layer != []:
                my_model.add(Conv2D(layer[0], layer[1], name=f'conv{i}',padding="same")) #Add conv parameters
                if layer[3] == 1:  my_model.add(Activation(relu))
                if layer[2] != 0: my_model.add(MaxPool2D((layer[2],layer[2]),padding="same"))
    
        my_model.add(Flatten())

        for i,layer in enumerate(dense_layers):
            if layer != []:
                my_model.add(Dense(layer[0]))
                if layer[1] == 1:  my_model.add(Activation(relu))
    else:
        print("Erreur de version dans le parametre version")
    
    my_model.add(Dense(nb_classe,activation=softmax))

    my_model.compile(loss=loss, optimizer=optimizer, metrics=[mertics])

    return my_model



def CreateModel2(optimizer=None,input_shape=(),nb_features=2, individual=[],
                version="dynamique",loss='categorical_crossentropy',
                mertics="accuracy"):
    """
        Fonction de ceation du 2eme modele utilisé detecter la minuties dnas les blocs
            -  Input Shape : dimension d'entré
            -  nb_feature: nombre de parametre predire
            -  individual: le chromosome de l'individu
            -  version: version de l'encodage soit "dynamique" ou "statique"
            -  loss: la fonction erreur
            -  metrics: metrique d'evaluation
    """
    my_model = Sequential(name="Model")
    my_model.add(Input(shape=input_shape))
    #my_model.add(Reshape((28,28,1)))

    conv_layers = individual[0]
    dense_layers = individual[1]

    if version=="dynamic":
        for i,layer in enumerate(conv_layers):
            my_model.add(Conv2D(layer[0], layer[1], name=f'conv{i}',padding="same")) #Add conv parameters
            if layer[3] == 1: my_model.add(Activation(relu))
            if layer[2] != 0: my_model.add(MaxPool2D((layer[2],layer[2]),padding="same"))

        my_model.add(Flatten())

        for i,layer in enumerate(dense_layers):
            my_model.add(Dense(layer[0]))
            if layer[1] == 1:  my_model.add(Activation(relu))

    elif version=="statique":
        for i,layer in enumerate(conv_layers):
            if layer != []:
                my_model.add(Conv2D(layer[0], layer[1], name=f'conv{i}',padding="same")) #Add conv parameters
                if layer[3] == 1:  my_model.add(Activation(relu))
                if layer[2] != 0: my_model.add(MaxPool2D((layer[2],layer[2]),padding="same"))
    
        my_model.add(Flatten())

        for i,layer in enumerate(dense_layers):
            if layer != []:
                my_model.add(Dense(layer[0]))
                if layer[1] == 1:  my_model.add(Activation(relu))
    else:
        print("Erreur de version dans le parametre version")
    
    my_model.add(Dense(nb_features))
    my_model.compile(loss=loss, optimizer=optimizer, metrics=[mertics])

    return my_model

"""#4. Genetic Algorithme

## Search space
"""

nb_bloc_conv_valeus = [3,4,5,6]
nb_filters_valeus = [32,64,128,256] #[10,20,30,40]
filter_size_valeus = [3,5,7,9]
nb_dense_layer_valeus = [1,2,3]
nb_dense_units_valeus = [64,128,256,512]
polling_size_valeus = [0,3,5] #Dans le cas ou c'est 0 on ajoute pas de pooling

learning_rate = [0.1,0.01,0.02,0.001,0.002,0.0001] 

search_space_conv = [nb_filters_valeus,filter_size_valeus,polling_size_valeus,[0,1]]
search_space_dense = [nb_dense_units_valeus,[0,1]]

"""## Population generation"""

def InitPopulation(population_size,version="dynamic"):

    population = []
    individual = []
    conv_layers =  []
    layer = []
    dense_layers = []

    for i in range(0,population_size):
    
        conv_layers =  []
        nb_conv_layers = random.choice(nb_bloc_conv_valeus)
        for j in range(nb_conv_layers):
            layer.append(random.choice(nb_filters_valeus))
            layer.append(random.choice(filter_size_valeus))
            layer.append(random.choice(polling_size_valeus))
            layer.append(random.choice([0,1])) #Choixe d'ajouter ou pas une couche d'activation
            conv_layers.append(layer)
            layer = []
        
        if version == "static":
            for i in range(nb_conv_layers, max(nb_bloc_conv_valeus)):
                conv_layers.append([])
        
        individual.append(conv_layers)
        
        dense_layers = []
        nb_dense_layers = random.choice(nb_dense_layer_valeus)
        for j in range(nb_dense_layers):
            layer.append(random.choice(nb_dense_units_valeus))
            layer.append(random.choice([0,1])) #Choix d'ajouter ou pas une couche d'activation
            dense_layers.append(layer)
            layer=[]
        
        if version =="static":
            for i in range(nb_dense_layers, max(nb_dense_layer_valeus)):
                dense_layers.append([])

        individual.append(dense_layers)

        population.append(individual)
        print(copy.deepcopy(individual))
        individual = []

    return population

"""## Evaluation"""

def Fitness(version_encodage,individual,optimizer=None,input_shape=(),
                     nb_classe=2,train_set = [],
                     test_set=[],nb_epochs = 4, 
                     batch_size = 100,validation_split = 0.2):
    try:
        
        model = CreateModel1(optimizer=optimizer,input_shape=input_shape,
                             nb_classe=nb_classe,individual=individual,version=version_encodage)
        history = model.fit(x = train_set[0], batch_size=batch_size, epochs=nb_epochs,verbose=0)
        
        train_acc = max(history.history['accuracy'])
        test_loss, test_acc = model.evaluate(test_set[0], steps=len(test_set[0]))
        
    except:
        return 0,0,0
    
    
    return train_acc,test_loss,test_acc

def EvaluatePopulation(version_endcodage,population = [], optimizer = None,input_shape=(),
                        DataBase=[], nb_epochs = 15,
                        batch_size = 50,paths:dict = None):

    evaluation = []
    if len(DataBase[0]) != 0: 
        
        for i,individual in enumerate(population):
            print("Evaluation individu: ",i)
            
            train_acc, fitness, time_, exist = CheckInMemorie(paths["MemorieFile"],individual)
            
            if not exist:

                debut = time.time()
                train_acc, test_loss, fitness = Fitness(version_endcodage,optimizer=optimizer, individual = individual,input_shape=input_shape,
                                        train_set=DataBase[0],test_set=DataBase[1],nb_epochs=nb_epochs,batch_size=batch_size)
                #evaluated_population[tuple(individual)] = fitness
                fin = time.time()
                time_ = fin-debut
                AddToMemorie(paths["MemorieFile"], individual,train_acc,fitness, time_)

            data = {"train accuracy":round(train_acc,4),"test accuracy":round(fitness,4),"time":round(time_,2)}
            WriteOnCSV(paths["CSVFile"],data)
            
            AddToResults(paths["ResultsFile"],i,individual,round(fitness,4),round(train_acc,4),round(time_,4),round(time_/nb_epochs,4))

            evaluation.append((copy.deepcopy(individual),fitness))

            with open(paths["TextFile"],"a") as f:
                f.write(f"{individual}\n")
            f.close()
            print(f"Train accuracy:{round(train_acc,4)} Test accuracy:{round(fitness,4)} temp: {round(time_,2)}")
    return evaluation




def WriteOnCSV(file_path, data):
    file = open(file_path, "a",newline='')
    writer = csv.DictWriter(file, fieldnames=list(data.keys()))
    writer.writerow(data)
    file.close()

def AddToMemorie(file_path, individual, train_acc,fitness,time):
    try:
        with open(file_path, 'r') as file:
            data = json.load(file)

        newkey =  f"individual{len(data)+1}"

        data[newkey] = {
            "individual": individual,
            "train_acc":train_acc,
            "fitness":fitness,
            "time":time
        }

        with open(file_path,"w") as file:
            json.dump(data,file)
    except(json.decoder.JSONDecodeError):
        
        data = {"individual1": {
            "individual": individual,
            "train_acc":train_acc,
            "fitness":fitness,
            "time":time
        }}

        with open(file_path,"w") as file:
            json.dump(data,file)

def CheckInMemorie(file_path:str, individu):
    
    try:
        with open(file_path, 'r') as file:
            data = json.load(file)

        for list in data:
            if data[list]["individual"] == individu:
                print("Trouvé", individu)
                return data[list]["train_acc"], data[list]["fitness"],data[list]["time"], True
    
    except (FileNotFoundError, json.decoder.JSONDecodeError):
        return 0,0,0,False 
     
    return 0,0,0, False


def AddToResults(file_path:str,nb_gener, individual, fitness,train_acc, time, time_per_epoch):
    pass
"""## Selection"""

def SelectNextGeneration(population = [],children=[],generation_size=10, elite_frac = 0.5, children_frac = 0.5):
  
    nb_population = int(generation_size*elite_frac)
    nb_children = int(generation_size*children_frac)

    population_sorted = sorted(population, key=lambda x: x[1], reverse=True)  

    next_generation = []
    next_generation +=  [copy.deepcopy(indiv[0]) for indiv in population_sorted[0:nb_population]]
    print("selected individus:")
    for indi in next_generation:
        print(indi)
    next_generation += copy.deepcopy(list(random.sample(children,nb_children)))

    if (nb_population+nb_children) < generation_size :
        nb_random_indivs = int((1 - (elite_frac+children_frac)) * generation_size)

        for i in range(nb_random_indivs):
            random_number = random.sample(list(population.keys()),nb_random_indivs)

    return next_generation

def SelectBestSolution(population = []):
    sorted_population = sorted(population, key=lambda x: x[1])
    return sorted_population[-1]


def BestRankedSelection(nb_parents, population:list):

    population_sorted = sorted(population, key=lambda x: x[1],reverse=True)
    parents  = [parent[:] for parent in [indiv[0][:] for indiv in population_sorted]][0:nb_parents]
    
    return parents

def rank_selection(population, num_parents):
    fitness = [individual.fitness for individual in population]
    rank = np.argsort(np.argsort(fitness))[::-1]
    selected_parents = []
    for i in range(num_parents):
        rand = np.random.randint(0, sum(range(len(rank)))+1)
        for j in range(len(rank)):
            rand -= j
            if rand < 0:
                selected_parents.append(population[rank[j]])
                break
    return selected_parents

def random_selection(population, nb_parents):
    selected = []
    parents = []
    for i in range(nb_parents):
        r = random.randint(0,len(population))
        while r in selected:
            r = random.randint(0,len(population))
    
        selected.append(r)
        parents.append(list(population.keys())[r])
  
    return parents


def SelectionAphaBeta(population,children, alpha, beta):
    
    pass

"""## Corossover"""

def CrossoverConv(parent1, parent2, proba_crossover = 0.7):
    """
        Crossover applique sur la partie des couches convolution
            -  proba_crossover: la probabilité de faire un crossover
    """
    parent_1 = copy.deepcopy(parent1)
    parent_2 =copy.deepcopy(parent2)
    if random.random() < proba_crossover:
        child_1,child_2 = [],[]
        min_length = min(len(parent_1[0]),len(parent_2[0]))
        random_point = random.randint(0,min_length)
        child_1.append(parent_1[0][0:random_point]+parent_2[0][random_point:len(parent_2[0])])
        child_2.append(parent_2[0][0:random_point]+parent_1[0][random_point:len(parent_1[0])])
        min_length = min(len(parent_1[1]),len(parent_2[1]))
        random_point = random.randint(0,min_length)
        child_1.append(parent_1[1])
        child_2.append(parent_2[1])

        return copy.deepcopy(child_1),copy.deepcopy(child_2)
    else:
        return parent_1, parent_2

def CrossoverDense(parent1, parent2, proba_crossover=0.7):
    """
        Crossover applique sur la partie des couches fully connected
            -  proba_crossover: la probabilité de faire un crossover
    """
    parent_1 = copy.deepcopy(parent1)
    parent_2 =copy.deepcopy(parent2)
    if random.random() < proba_crossover:
        child_1,child_2 = [],[]
        min_length = min(len(parent_1[0]),len(parent_2[0]))
        random_point = random.randint(0,min_length)
        child_1.append(parent_1[1][0:random_point]+parent_2[1][random_point:len(parent_2[0])])
        child_2.append(parent_2[1][0:random_point]+parent_1[1][random_point:len(parent_1[0])])
        min_length = min(len(parent_1[1]),len(parent_2[1]))
        random_point = random.randint(0,min_length)
        child_1.append(parent_1[0])
        child_2.append(parent_2[0])

        return child_1,child_2
    else:
        return parent_1, parent_2

def Crossover2Parties(parent1, parent2, proba_crossover):
    """
        Crossover applique sur les deux parties du chromosome
            -  proba_crossover: la probabilité de faire un crossover
    """
    parent_1 = copy.deepcopy(parent1)
    parent_2 = copy.deepcopy(parent2)
    if random.random() < proba_crossover:
        child_1,child_2 = [],[]
        min_length = min(len(parent_1[0]),len(parent_2[0]))
        random_point = random.randint(0,min_length)
        child_1.append(parent_1[0][0:random_point]+parent_2[0][random_point:len(parent_2[0])])
        child_2.append(parent_2[0][0:random_point]+parent_1[0][random_point:len(parent_1[0])])
        min_length = min(len(parent_1[1]),len(parent_2[1]))
        random_point = random.randint(0,min_length)
        child_1.append(parent_1[1][0:random_point]+parent_2[1][random_point:len(parent_2[1])])
        child_2.append(parent_2[1][0:random_point]+parent_1[1][random_point:len(parent_1[1])])

        return copy.deepcopy(child_1),copy.deepcopy(child_2)
    else:
        return parent_1, parent_2


def UniformCrossover(parent1,parent2,proba_crossover):
    """
        Crossover uniforme applique sur les deux parties du chromosome 
            -  proba_crossover: la probabilité de faire un crossover
    """
    parent_1 = parent1[:]
    parent_2 = parent2[:]
    child_1, child_2 = [[],[]],[[],[]]

    for i in range(len(parent_1[0])):
        if random.random() < proba_crossover: 
            child_1[0][i] = parent_1[0][i]
            child_2[0][i] = parent_2[0][i]
        else : 
            child_1[0][i] = parent_2[0][i]
            child_2[0][i] = parent_1[0][i]

    for i in range(len(parent_1[1])):
        if random.random() < proba_crossover: 
            child_1[1][i] = parent_1[1][i]
            child_2[1][i] = parent_2[1][i]
        else : 
            child_1[1][i] = parent_2[1][i]
            child_2[1][i] = parent_1[1][i]

    return child_1,child_2

"""## Mutation"""


def AddConvLayer(child,i=0,version="dynamic"):
    individual = copy.deepcopy(child)
    layer = []

    if version == "dynamic":
        if len(individual[1])<max(nb_bloc_conv_valeus):
        
            layer.append(random.choice(nb_filters_valeus))
            layer.append(random.choice(filter_size_valeus))
            layer.append(random.choice(polling_size_valeus))
            layer.append(random.choice([0,1]))

            rand_pos = random.randint(0,len(individual[0]))

            individual[0].insert(rand_pos,layer)
            
    else:

        layer.append(random.choice(nb_filters_valeus))
        layer.append(random.choice(filter_size_valeus))
        layer.append(random.choice(polling_size_valeus))
        layer.append(random.choice([0,1]))

        individual[0][i] =copy.deepcopy(layer)
        
    return copy.deepcopy(individual)
  

def DelConvLayer(child,i=0,version="dynamic"):
    individual = copy.deepcopy(child)
    if version == "dynamic":
        if len(individual[0]) > min(nb_bloc_conv_valeus):
            rand_layer = random.randrange(0,len(individual[0]))
            del individual[0][rand_layer]

        
    else:
        individual[0][i] = []
        
    return copy.deepcopy(individual)

def AlterConvLayer(child,i=0,version="dynamic"):
    individual = copy.deepcopy(child)
    if version=="dynamic":
        rand_layer = random.randrange(0,len(individual[0]))
        rand_param = random.randrange(0,len(search_space_conv))
        val_selected = random.choice(search_space_conv[rand_param])

        while val_selected == individual[0][rand_layer][rand_param]:
            val_selected = random.choice(search_space_conv[rand_param])

        individual[0][rand_layer][rand_param] = val_selected
        
    else:
        rand_param = random.randrange(0,len(individual[0][i]))
        val_selected = random.choice(search_space_conv[rand_param])
        while val_selected == individual[0][i][rand_param]:
            val_selected = random.choice(search_space_conv[rand_param])
        individual[0][i][rand_param] = val_selected
    
    return copy.deepcopy(individual)

def AddDenseLayer(child,i=0,version="dynamic"):
    individual = copy.deepcopy(child)
    layer = []
    if version == "dynamic":
        if len(individual[1])<max(nb_dense_layer_valeus):
            layer.append(random.choice(nb_dense_units_valeus))
            layer.append(random.choice([0,1]))

            rand_pos = random.randint(0,len(individual[1]))

            individual[1].insert(rand_pos,layer)
    else:
        layer.append(random.choice(nb_dense_units_valeus))
        layer.append(random.choice([0,1]))

        individual[1][i] = layer
    
    return copy.deepcopy(individual)
  

def DelDenseLayer(child,i=0,version="dynamic"):
    individual = copy.deepcopy(child)
    if version == "dynamic":
        if len(individual[1]) > min(nb_dense_layer_valeus):
            rand_layer = random.randrange(0,len(individual[1]))
            del individual[1][rand_layer]
    else:
        individual[1][i] = []
    
    return copy.deepcopy(individual)
  

def AlterDenseLayer(child,i=0,version="dynamic"):
    individual = copy.deepcopy(child)
    if version=="dynamic":

        rand_layer = random.randrange(0,len(individual[1]))
        rand_param = random.randrange(0,len(individual[1][0]))
        val_selected = random.choice(search_space_dense[rand_param])

        while val_selected == individual[1][rand_layer][rand_param]:
            val_selected = random.choice(search_space_dense[rand_param])

        individual[1][rand_layer][rand_param] = val_selected

    else:
        rand_param = random.randrange(0,len(individual[1][i]))
        val_selected = random.choice(search_space_dense[rand_param])
        while val_selected == individual[1][i][rand_param]:
            val_selected = random.choice(search_space_dense[rand_param])
        individual[1][i][rand_param] = val_selected

    return copy.deepcopy(individual)

def Mutation(child, proba_mutation=1, version="dynamic"):
    
    if random.random() > proba_mutation:
        return copy.deepcopy(child)

    individual = copy.deepcopy(child)
    
    if version == "dynamic":
        
        rand_operation = random.choice([1,2,3])

        while rand_operation==2 and len(individual[1]) == min(nb_dense_layer_valeus):
            rand_operation = random.choice([1,2,3])

        if rand_operation == 1:individual = AddDenseLayer(individual,version=version)[:]
        elif rand_operation == 2:individual = DelDenseLayer(individual,version=version)[:]
        else:individual = AlterDenseLayer(individual,version=version)[:]

        rand_operation = random.choice([1,2,3])

        rand_operation = random.choice([1,2,3])
        while rand_operation==2 and len(individual[0]) == min (nb_bloc_conv_valeus):
            rand_operation = random.choice([1,2,3])

        if rand_operation == 1: individual = AddConvLayer(individual,version=version)[:]
        elif rand_operation == 2:individual = DelConvLayer(individual,version=version)[:]
        else: individual = AlterConvLayer(individual,version=version)[:]
    
    elif version == "static":

        count1, count2 = 0,0
        del_layer_conv, del_layer_dense = True,True

        for layer in individual[0]: 
            if layer == []: count1 += 1
        if count1<= min(nb_bloc_conv_valeus): del_layer_conv = False

        for layer in individual[1]:
                if layer == []:count2 += 1
        if count2<= min(nb_dense_layer_valeus): del_layer_dense = False
            

        rand_layer = random.randrange(0,max(nb_bloc_conv_valeus))

        if individual[0][rand_layer]!=[] and del_layer_conv == True:
            
            rand_operation = random.choice([1,2])
            if rand_operation == 0: individual = AlterConvLayer(individual, rand_layer,version=version)[:]
            else: individual = DelConvLayer(individual,rand_layer,version=version)[:]

        elif individual[0][rand_layer] != [] and del_layer_conv == False:
            individual = AlterConvLayer(individual, rand_layer,version=version)[:]

        else :
            individual = AddConvLayer(individual, rand_layer,version=version)[:]

        rand_layer = random.randrange(0,max(nb_dense_layer_valeus))

        if individual[1][rand_layer]!=[] and del_layer_dense== True:
            
            rand_operation = random.choice([1,2])
            if rand_operation == 0: individual = AlterDenseLayer(individual, rand_layer,version=version)[:]
            else: individual = DelDenseLayer(individual,rand_layer,version=version)[:]

        elif individual[1][rand_layer] != [] and del_layer_dense == False:
            individual = AlterDenseLayer(individual, rand_layer,version=version)[:]
        else :  individual = AddConvLayer(individual, rand_layer,version=version)[:]     
        
    else:
        print("Erreur de version")
    return copy.deepcopy(individual)

"""## Algorithme"""

def GeneticAlgorithme(version_encodage,population_size, nb_generation,nb_parents,elite_frac,
                      children_frac,optimizer,input_shape,DataBase, 
                      nb_epochs,batch_size,proba_crossover,proba_mutation,paths ):
    best_in_generation = []
    #initalise la population aleatoirement
    population = InitPopulation(population_size,version_encodage)
    
    population_evaluated = EvaluatePopulation(version_encodage,population=population,optimizer=optimizer,input_shape=input_shape,DataBase=DataBase, 
                                        nb_epochs=nb_epochs,batch_size=batch_size, paths=paths)
    best_in_generation.append(SelectBestSolution(population_evaluated))

    for i in range(nb_generation):
    
        with open(paths["TextFile"], "a") as f:
            f.write(f"Generation:{i} \n")
        f.close()

        print("Debut generation: ",i)

        parents = BestRankedSelection(nb_parents,population_evaluated)
        
        #Appliquer le crossover pour cree de nouveau enfants
        new_children = []
        for parent_1, parent_2 in combinations(parents,2):
            
            #appliquer le crossover sur chaque 2 de parents
            child_1,child_2 = Crossover2Parties(parent_1,parent_2,proba_crossover)
            new_children.append(child_1)
            new_children.append(child_2)

        #Appliquer la mutation sur les enfants
        children_after_mutation = []
        for child in new_children:
            mutated_child = Mutation(copy.deepcopy(child),proba_mutation,version=version_encodage)
            children_after_mutation.append(copy.deepcopy(mutated_child))
        
        #selection la population de la future generation
        population = SelectNextGeneration(population_evaluated, children_after_mutation,population_size,elite_frac,children_frac)
        
        
        #Evaluer la population
        population_evaluated = EvaluatePopulation(version_encodage,population=population,optimizer=optimizer,input_shape=input_shape, DataBase=DataBase, 
                                        nb_epochs=nb_epochs,batch_size=batch_size, paths=paths)
        best_in_generation.append(SelectBestSolution(population_evaluated))
    
    #Selectionner la meilleur solution attiente
    #best_in_generation = SelectBestSolution(population_evaluated, best_in_generation)

    return best_in_generation

"""#4. Datas"""

def LoadDataBase(TrainingPath:str, TestPath:str,batchsize=150):

    train_datagen = ImageDataGenerator(
        rescale=1./255,
        horizontal_flip=True,
        validation_split=0.2)

    training_set= train_datagen.flow_from_directory(
        TrainingPath,
        target_size=(32, 32),
        color_mode="grayscale",
        batch_size=batchsize,
        class_mode='categorical'
        )
    
    
    test_datagen = ImageDataGenerator(
            rescale=1./255)

    test_set= test_datagen.flow_from_directory(
            TestPath,
            target_size=(32, 32),
            color_mode="grayscale",
            batch_size=batchsize,
            class_mode='categorical'
            )
    
    return training_set,test_set



def LoadDataBase2(DataSet_Path:str,Images_Path:str, TestSplit=0.3):
  
  TrainSet_X, TestSet_X= [],[],[],[],
  df = pd.read_csv(DataSet_Path)
  Train, Test = train_test_split(df, test_size=TestSplit,shuffle=True)


  for path in Train["Images"]:
    img = cv.imread(Images_Path+"/"+path, cv.IMREAD_GRAYSCALE)
    img = cv.reshape(img,(32,32,1))

    TrainSet_X.append(img)

  for path in Test["Images"]:
    img = cv.imread(Images_Path+"/"+path, cv.IMREAD_GRAYSCALE)
    img = cv.reshape(img,(32,32,1))

    TestSet_X.append(img)

  TrainSet_Y = Train[["X","Y"]]
  TestSet_Y = Test[["X","Y"]]
  

  return TrainSet_X,TestSet_X,TrainSet_Y, TestSet_Y

"""# Test"""

NB_OF_GENERATION = 10
POPULATION_SIZE = 20
NB_PARENTS = 10
INPUT_SHAPE =(32,32,1)
BATCH_SIZE = 150
NB_EPOCHS = 8
ELITE_FRAC = 0.5
CHILDREN_FRAC = 0.5
TEST_SIZE = 0.4
PROBA_MUTATION = 0.7
PROBA_CROSSOVER = 0.7
VERSION_ENCODAGE = "dynamic"
LEARNING_RATE = 0.02

date = datetime.datetime.now()
date = date.strftime("%m_%d_%H_%M_%S")


PATHS = {
    "TextFile":f"Tests/file_{date}.txt",
    "CSVFile":f"Tests/file_{date}.csv",
    "MemorieFile":"Tests/memorie.json",
    "ResultsFile":"Tests/results.json"
}

f = open(PATHS["TextFile"],"w")
f.write(f"NB_OF_GENERATION = {NB_OF_GENERATION}\nPOPULATION_SIZE = {POPULATION_SIZE}\nINPUT_SHAPE "+
        f"= {INPUT_SHAPE}\nBATCH_SIZE = {BATCH_SIZE}\nNB_EPOCHS = {NB_EPOCHS}\nELITE_FRAC = {ELITE_FRAC}\nCHILDREN_FRAC = "+
        f"{CHILDREN_FRAC}\nTEST_SIZE = {TEST_SIZE}\nPROBA_MUTATION = {PROBA_MUTATION}\n"+
        f"PROBA_CROSSOVER = {PROBA_CROSSOVER}\nVERSIONEN_CODAGE = {VERSION_ENCODAGE}\n")

f.close()

if not os.path.isfile(PATHS["CSVFile"]):
    columns = ["train accuracy", "test accuracy", "time"]
    csv_file = open(PATHS["CSVFile"], 'w',newline='')
    writer = csv.DictWriter(csv_file,fieldnames=columns)
    writer.writeheader()
    csv_file.close()

csv_file = "/content/Dataset/BaseDeDonnees_2/Labels.csv"
image_path = "/content/Dataset/BaseDeDonnees_2/Images" 

TrainSet_X,TestSet_X,TrainSet_Y, TestSet_Y = LoadDataBase2(csv_file,image_path)


Database = [[TrainSet_X,TrainSet_Y],[TestSet_X,TestSet_Y]]
optimizer = SGD(LEARNING_RATE)
best_solution = GeneticAlgorithme(VERSION_ENCODAGE,POPULATION_SIZE,NB_OF_GENERATION,NB_PARENTS,
                                  ELITE_FRAC,CHILDREN_FRAC,optimizer,INPUT_SHAPE,Database,NB_EPOCHS,BATCH_SIZE,PROBA_CROSSOVER,PROBA_MUTATION,PATHS)
print("Best Solution: ",best_solution)

#!cp -r "file_{date}.txt" "/content/drive/MyDrive/Colab Notebooks/Projet Master/Tests/file_{date}.txt"